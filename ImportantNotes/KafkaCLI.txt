Creating a new topic in Kafka Server with Kafka CLI (Command Line Interface)
1) Open the windows command prompt and start the wsl (Windows Subsystem For Linux)
2) Navigate to Kafka directory with command "cd kafka_2.13-4.1.0"
3) Check if you are currently using the kafka_2.13-4.1.0 directory with "pwd" command
4) Start the Kafka server using the command: bin/kafka-server-start.sh config/server.properties
5) Open new command prompt and start the new "wsl" & navigate to the "cd kafka_2.13-4.1.0" again
6) Then navigate to the bin directory with command "cd bin"
7) Now run the command: "./kafka-topics.sh --create --topic <Name for your Kafka topic> --partitions <Specify your number of partitions> --replication-factor <Specify the number of replication factor> --bootstrap-server <Pass the Address of your running Kafka Server>"
Example: "./kafka-topics.sh --create --topic topicOne" --partitions 3 --replication-factor 3 --bootstrap-server localhost:9092"
If above command didn't worked then use the command: "./kafka-topics.sh --create --topic topicOne --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092"
8) In above command we are creating the new kafka topic called "topicOne" which has 3 "partitions" and 3 "replication-factor" with server running on localhost:9092
9) Important Note:
    I) While Giving the topic name after (--topic <Name for your Kafka topic>) this command you should use the Business Specific Naming Convention
    II) When you specify the number of partitions then, it is mandatory that your number of partitions should always be greater than number of consumers
    III) Number of "partitions" should be greater than number of consumers, Once you specify the value then it is irreversible.
    IV) Number of "replication-factor" should not be greater than the number of brokers present inside your cluster
10) After topics are created now List down the topics in Kafka Server with command "./kafka-topics.sh --list --bootstrap-server localhost:9092"
11) Now to see the topic description use the command: "./kafka-topics.sh --describe --bootstrap-server localhost:9092"
12) Now to delete the Kafka topic use the command: "bin/kafka-topics.sh --delete --topic <your-topic-name> --bootstrap-server localhost:9092"
Example: ./kafka-topics.sh --delete --topic topicOne --bootstrap-server localhost:9092
./kafka-topics.sh --delete --topic test-topic --bootstrap-server localhost:9092
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Important commands related to the Kafka topic creation
# List topics
bin/kafka-topics.sh --list --bootstrap-server localhost:9092
bin/kafka-topics.sh --bootstrap-server 172.30.177.3:9092 --list
# Create topic
bin/kafka-topics.sh --create --topic test-topic --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092
# Describe topic
bin/kafka-topics.sh --describe --topic test-topic --bootstrap-server localhost:9092
# Delete topic
bin/kafka-topics.sh --delete --topic test-topic --bootstrap-server localhost:9092
------------------------------------------------------------------------------------------------------------------------------------------
Apache Kafka CLI for Producers to send the message to Kafka topic
1) Open the windows command prompt and start the wsl (Windows Subsystem For Linux)
2) Navigate to Kafka directory with command "cd kafka_2.13-4.1.0"
3) Check if you are currently using the kafka_2.13-4.1.0 directory with "pwd" command
4) Open the bin directory using the command "cd bin"
5) Now create a topic with command : ./kafka-topics.sh --create --topic topicOne --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092
6) Then run the command  "./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic topicOne"
7) Then send message called "Hello World" to the topic by typing the message in the empty space of command prompt
8) Important Note: If topic does not exists then Kafka will create the new topic by default if we set the value "auto.create.topics.enable=true" in server.properties
9) After sending the message to kafka, console will keep open for sending more messages, to stop the messaging press "Ctrl + C" to exit
10) Messages in the Kafka topic will be stored in the Key-Value Pairs, if we send message without key then key will be null
11) Messages with same key will be stored in same partitions and if they are present in same partitions then that means they are in ordered manner
12) To send messages with keys we need to add few additional properties in above command to enable it for key-value support
13) Key-Value Pair Command: ./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic topicOne --property "parse.key=true" --property "key.separator=:"
14) Now send the message as {firstName:Ratnakar} Here key=firstName & Value=Ratnakar
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Fetch and Display the messages from Kafka topic with Consumers
1) Command Example: bin/kafka-console-consumer.sh --topic my-topic --from-beginning --bootstrap-server-localhost:9092
2) Navigate to Kafka directory with command "cd kafka_2.13-4.1.0"
3) Check if you are currently using the kafka_2.13-4.1.0 directory with "pwd" command
4) Open the bin directory using the command "cd bin"
5) Then use the command: ./kafka-console-consumer.sh --topic topicOne --from-beginning --bootstrap-server-localhost:9092
6) In above command "--from-beginning" syntax will display all the messages in real time for all the producers
7) In Kafka once consumer consumes the message it does not destroy it keeps the message in the topic so that other consumers can consume it as well
8) As soon as message is sent to topic all consumers who are subscribed to it will consume the message and display it on the console
9) To consume only new messages from Kafka topic we removed the "--from-beginning" this command from above command, So our new command will be ./kafka-console-consumer.sh --topic topicOne --bootstrap-server localhost:9092
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Consuming Key-Value Pair Messages from Kafka
1) By default consumer only read the value only
2) To read the messages that sent as Key-Value Pairs modify the above command as : ./kafka-console-consumer.sh --topic topicOne --from-beginning --bootstrap-server localhost:9092 --property print.key=true
3) To hide the values and print only Keys use the command as: ./kafka-console-consumer.sh --topic topicOne --from-beginning --bootstrap-server localhost:9092 --property print.value=false
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Read the messages from topic in the order
1) To read the messages from topic in ordered manner use the command : ./kafka-console-consumer.sh --topic topicOne --from-beginning --bootstrap-server localhost:9092 --property print.key=true
2) Messages with same key will always be published in order while messages with different key will be published randomly
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
./kafka-console-consumer.sh --topic product-created-events-topic --from-beginning --bootstrap-server 172.30.177.3:9092 --property print.key=true
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
To create the minimum amount of insync replicas property at the time of creating new topic then we will use the following command
1) Command for creating new topic with insync replicas:
./bin/kafka-topics.sh --create --topic insync-topic --partitions 1 --replication-factor 2 --bootstrap-server 172.30.177.3:9092 --config min.insync.replicas=2
2) Command for creating insync replicas for existing topic:
./bin/kafka-configs.sh --bootstrap-server 172.30.177.3:9092 --alter --entity-type topics --entity-name product-created-events-topic --add-config min.insync.replicas=2
3) Run the describe topic command to check if our topic replicas are updated successfully
./bin/kafka-topics.sh --describe --bootstrap-server 172.30.177.3:9092
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Create new topic with insync replicas
./bin/kafka-topics.sh --create --topic insync-topic --partitions 1 --replication-factor 1 --bootstrap-server 172.30.177.3:9092 --config min.insync.replicas=1
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Idempotent producer:
An idempotent producer makes sure that each message is written once and only once to a Kafka topic partition, even when the producer internally retries sending that message.
In Apache Kafka, an idempotent producer is a Kafka producer configured to guarantee exactly-once write semantics per partition, ensuring that duplicate messages are not written, even if retries happen due to network issues, timeouts, or broker failures.
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Kafka Producer & Consumer Script for error handling testing
1) ./bin/kafka-console-producer.sh --bootstrap-server 172.30.177.3:9092 --topic product-created-events-topic --property "parse.key=true" --property "key.separator=:"
2) ./bin/kafka-console-consumer.sh --topic product-created-events-topic --from-beginning --bootstrap-server 172.30.177.3:9092 --property print.key=true
3) For Dead Letter topic please refer the "KafkaDeadLetterTopic.txt" document